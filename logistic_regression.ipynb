{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Implement Logistic Regression from Scratch\n",
    "\n",
    "- [book](http://math.ecnu.edu.cn/~lfzhou/seminar/[Joel_Grus]_Data_Science_from_Scratch_First_Princ.pdf) \n",
    "- [resource](https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html)\n",
    "- [logistic regression cost fnction derivative](https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)\n",
    "- [source code](https://github.com/bfortuner/ml-glossary/tree/master/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.array):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic function property\n",
    "\n",
    "As its \n",
    "- input gets **large and positive**, it gets closer and closer to `1`. \n",
    "- As its input gets **large and negative**, it gets closer and closer to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.53978687e-05]), array([0.5]), array([0.9999546]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-10])), sigmoid(np.array([0])), sigmoid(np.array([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic function derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.researchgate.net/profile/Farid_Najafi/publication/268874045/figure/fig2/AS:295410393468928@1447442734016/Graph-of-the-dynamic-logistic-function-and-its-derivative-function-for-active-input-range.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x: np.array):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.53978687e-05, 4.53978687e-05]),\n",
       " array([0.5, 0.5]),\n",
       " array([0.9999546, 0.9999546]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-10,-10])), sigmoid(np.array([0,0])), sigmoid(np.array([10,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.53958077e-05, 4.53958077e-05]),\n",
       " array([0.25, 0.25]),\n",
       " array([4.53958077e-05, 4.53958077e-05]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_prime(np.array([-10,-10])), sigmoid_prime(np.array([0,0])), sigmoid_prime(np.array([10,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Loss Function (Cost function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use a cost function called **Cross-Entropy**, also known as `Log Loss`. Cross-entropy loss can be divided into two separate cost functions: \n",
    "- one for $ùë¶=1$\n",
    "- one for $ùë¶=0$\n",
    "\n",
    "![image](https://ml-cheatsheet.readthedocs.io/en/latest/_images/ng_cost_function_logistic.png)\n",
    "\n",
    "**Above functions compressed into one**\n",
    "\n",
    "![image](https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_cost_function_joined.png)\n",
    "\n",
    "**Vectorized cost function**\n",
    "\n",
    "![image](https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_cost_function_vectorized.png)\n",
    "\n",
    "- [source](https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "h = prediction = sigmoid(x@w.T)\n",
    "\n",
    "x <- dimension 4,3\n",
    "y <- dimension 4,1\n",
    "w <- dimension 1,3\n",
    "\n",
    "h = sigmoid(x@w.T) <- dimesion 4,1\n",
    "log(h) <- dimension (4,1)\n",
    "```\n",
    "\n",
    "$y^T*\\log(h)$ <- dimension 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: np.array, w: np.array):\n",
    "    '''\n",
    "    Returns 1D array of probabilities\n",
    "    that the class label == 1\n",
    "    '''\n",
    "    return sigmoid(X@w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_hat: np.array, y: np.array):\n",
    "    '''\n",
    "    cost function = NEGATIVE LOG LIKELIHOOD\n",
    "    Using Mean Absolute Error\n",
    "\n",
    "    y: Labels: (100,1)\n",
    "    y_hat: predicted (100, 1)\n",
    "    m <- len(y)\n",
    "    Cost = (y*log(y_hat) + (1-y)*log(1-y_hat) ) / m\n",
    "    \n",
    "    Returns 1D matrix of predictions\n",
    "    '''\n",
    "    m = len(y)\n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = y*np.log(y_hat)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-y)*np.log(1-y_hat)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = (-1)*(class1_cost + class2_cost)\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum() / m\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(4,3)\n",
    "y = np.array([1,0,0,1]).reshape(-1, 1)\n",
    "w = np.random.rand(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831301744339975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(X, w)\n",
    "loss_fn(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://i.ytimg.com/vi/b4Vyma9wPHo/maxresdefault.jpg\" width=\"600\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function derivative\n",
    "\n",
    "![image](https://miro.medium.com/max/289/1*Nr2E9HL-RCDIW78VmBiJyg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "y_hat - y <- dimension 4,1  # assuming 4 records\n",
    "X <- feature <- dimension 4,3 # assuming 4 records and each record has 3 feature\n",
    "```\n",
    "\n",
    "X.T(y_hat - y) <- dimension 3, 1 # for 3 feature, 3 weight $w_1, \\dots, w_3$ ($\\theta_1, \\dots, \\theta_3$) and 3 partial derivatives $\\frac{\\partial L}{\\partial w_1}$, $\\frac{\\partial L}{\\partial w_2}$, $\\frac{\\partial L}{\\partial w_3}$ , but all values put inside a numpy vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_grad(X, y, w):\n",
    "    \"\"\"Calculate gradient of the loss function\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    y_hat = predict(X,w)\n",
    "    grad = (X.T @ (y_hat - y))/m\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13559734],\n",
       "       [0.10684298],\n",
       "       [0.11539397]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_grad(X, y, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "Repeat {\n",
    "\n",
    "  1. Calculate gradient average\n",
    "  2. Multiply by learning rate\n",
    "  3. Subtract from weights\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight(X, y, w, lr=0.01):\n",
    "    w -= lr*loss_fn_grad(X, y, w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(prob: float):\n",
    "    return 1 if prob >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, w, lr=0.01, epochs=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gradient decent algorithm, where at each epoch all the datasets are passed\n",
    "    It can be improved by using Stochastic gradient discent \n",
    "    \"\"\"\n",
    "    \n",
    "    loss_history = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        y_hat = predict(X, w)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        # update weight\n",
    "        w = update_weight(X, y, w, lr)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print(\"epoch: \"+str(i) + \" \\t loss: \"+str(np.round(loss,4)))\n",
    "\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([0,1], size=(4,1), p=[0.5,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = 8000\n",
    "nf = 10\n",
    "X = np.random.rand(nr,nf)\n",
    "y = np.random.choice([0,1], size=(nr,1), p=[0.4, 0.6])\n",
    "w = np.random.rand(nf,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (8000, 1), (10, 1))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t loss: 1.216\n",
      "epoch: 1000 \t loss: 0.9646\n",
      "epoch: 2000 \t loss: 0.8038\n",
      "epoch: 3000 \t loss: 0.7241\n",
      "epoch: 4000 \t loss: 0.6923\n",
      "epoch: 5000 \t loss: 0.6811\n",
      "epoch: 6000 \t loss: 0.6774\n",
      "epoch: 7000 \t loss: 0.6761\n",
      "epoch: 8000 \t loss: 0.6756\n",
      "epoch: 9000 \t loss: 0.6753\n",
      "epoch: 10000 \t loss: 0.6751\n",
      "epoch: 11000 \t loss: 0.6749\n",
      "epoch: 12000 \t loss: 0.6747\n",
      "epoch: 13000 \t loss: 0.6745\n",
      "epoch: 14000 \t loss: 0.6744\n",
      "epoch: 15000 \t loss: 0.6742\n",
      "epoch: 16000 \t loss: 0.6741\n",
      "epoch: 17000 \t loss: 0.6739\n",
      "epoch: 18000 \t loss: 0.6738\n",
      "epoch: 19000 \t loss: 0.6737\n"
     ]
    }
   ],
   "source": [
    "w_hat, loss_history = train(X, y, w, lr = 0.001, epochs=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
